Scraping is extracting information from webpage, filtering out and cleaning the data, then storing the data.

This could be triggered automatically when something changes in the webpage

Scraping data:
URL constant
import requests
import selectorlib

.get(url)
.text

if __name__

optional headers=HEADERS constant


Extracting data:
inspect element in browser and get ID

selectorlib.Extractor.from.yaml_file(extract.yaml)
create extract.yaml with tours and css with id displaytimer
.extract(source)["tours"]


if extracted data != no upcoming tours then check if extracted data != text file (in append mode), if not, store data in text file and send email.



SQL Databases
Speed in high volumes
Concurrency

DB browser for SQL is a GUI
Hierarchy: Databases -> Tables -> Rows and columns
Each colum has a type (text, integer, real/float)

use SQL Query
INSERT INTO
VALUES
SELECT FROM
DELETE FROM
WHERE
* (this means all)

sqlite3
.connect(db file)
.cursor()
.execute(SQL Query)
.fetchall()

list of tuples

.executemany(Query, new rows)

?  (this defines structure. two ? means two columns)

.commit()




